{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('y_train shape:', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_splits shape:  (10,)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n",
      "x shape:  (5000, 32, 32, 3) , y shape:  (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "from fedml import Alliance, AllianceMember,KerasSequentialBaseLearner, FedAveragingClassifier\n",
    "from read_data import read_training_data\n",
    "import numpy as np\n",
    "\n",
    "alliance = Alliance()\n",
    "M=10\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def split_data_noniid(x,y,fractions):\n",
    "    s = len(x)\n",
    "    l = np.eye(10)\n",
    "    sorted_ind=np.array([np.where([list(y_)==list(l[i]) for y_ in y])[0] for i in range(10)])\n",
    "    \n",
    "    parts=2\n",
    "    c = np.array([np.int32(np.linspace(0,len(sorted_ind[i]),parts+1)) for i in range(10)])\n",
    "    new_sorted_ind = np.array([[sorted_ind[i][c[i,j]:c[i,j+1]] for j in range(parts)] for i in range(10)])\n",
    "   \n",
    "    m = 10\n",
    "    x_list = np.empty(10,list)\n",
    "    y_list = np.empty(10,list)\n",
    "    \n",
    "    for i in range(10):\n",
    "        if i<9:\n",
    "            j=i+1\n",
    "        else:\n",
    "            j=0   \n",
    "        x_list[i] = np.concatenate((x[new_sorted_ind[i,0]],x[new_sorted_ind[j,1]]))\n",
    "        y_list[i] = np.concatenate((y[new_sorted_ind[i,0]],y[new_sorted_ind[j,1]]))\n",
    "        new_order = np.random.permutation(len(x_list[i]))\n",
    "        x_list[i] = x_list[i][new_order]\n",
    "        y_list[i] = y_list[i][new_order]\n",
    "\n",
    "    \n",
    "\n",
    "    return np.array(x_list),np.array(y_list)\n",
    "\n",
    "\n",
    "\n",
    "#F = [10,10,8,8,6,6,4,4,2,2,1,1]\n",
    "#M = len(F)\n",
    "\n",
    "x_train_splits, y_train_splits = split_data_noniid(x_train,y_train,fractions=10)\n",
    "print(\"x_train_splits shape: \", x_train_splits.shape)\n",
    "for x, y in zip(x_train_splits,y_train_splits):\n",
    "    print(\"x shape: \", x.shape, \", y shape: \", y.shape)\n",
    "#x_test_splits, y_test_splits = split_data(x_test,y_test,fractions=F)\n",
    "#print(\"x_train shape: \", np.array(x_train).shape)\n",
    "#tot_len = 0\n",
    "#for split in x_train_splits:\n",
    "#    print(\"x_train_splits shape: \", split.shape)\n",
    "#    tot_len += len(split)\n",
    "#print(\"tot len: \", tot_len)\n",
    "alliance.set_validation_dataset(x_test,y_test)\n",
    "\n",
    "classes = np.arange(10)\n",
    "for i in range(M):\n",
    "    member = AllianceMember(x_train_splits[i], y_train_splits[i], classes=classes)\n",
    "    alliance.add_member(member)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes for member  0 : [0 1]\n",
      "t: \n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "Classes for member  1 : [1 2]\n",
      "Classes for member  2 : [2 3]\n",
      "Classes for member  3 : [3 4]\n",
      "Classes for member  4 : [4 5]\n",
      "Classes for member  5 : [5 6]\n",
      "Classes for member  6 : [6 7]\n",
      "Classes for member  7 : [7 8]\n",
      "Classes for member  8 : [8 9]\n",
      "Classes for member  9 : [0 9]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for y in y_train_splits:\n",
    "    t = []\n",
    "    for y_ in y:\n",
    "        t += [np.argmax(y_)]\n",
    "    print(\"Classes for member \", i, \":\", np.unique(np.array(t)))\n",
    "    if i == 0:\n",
    "        print(\"t: \")\n",
    "        for j in range(100):\n",
    "            print(t[j])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-866d04d7742d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcifarmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasSequentialCifar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcifarmodelparameters\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decay\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbase_learner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasSequentialCifar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifarmodelparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfedavg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedAveragingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malliance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malliance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_learner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_learner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from cifarmodel import KerasSequentialCifar\n",
    "cifarmodelparameters= {\"optimizer\": keras.optimizers.Adam, \"learning_rate\": 0.1, \"decay\": 0}\n",
    "base_learner = KerasSequentialCifar(cifarmodelparameters)\n",
    "fedavg_model = FedAveragingClassifier(alliance=alliance,base_learner=base_learner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"nr_global_iterations\": 100, \"nr_local_iterations\":1, \"training_steps\": None, \"data_augmentation\": True, \"model_size_averaging\": True} \n",
    "training_loss, test_loss = fedavg_model.fit(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab as plt\n",
    "import pickle\n",
    "pickle.dump(fedavg_model.test_loss,open('test_loss_noniid_1epochloc.p','wb'))\n",
    "\n",
    "\n",
    "plt.plot(fedavg_model.test_loss)\n",
    "plt.savefig('accuracy_progress_noniid_1epochloc')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
